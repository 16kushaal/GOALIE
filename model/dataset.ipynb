{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff257ef",
   "metadata": {},
   "source": [
    "# This Notebook is to extract and generate the dataset as required for classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba87251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Login to Hugging Face using the token from environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955d47f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VI\\NLP\\football-score-extension-float\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\datasets--SoccerNet--SN-echoes. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating original split: 100%|██████████| 923181/923181 [00:00<00:00, 1309003.95 examples/s]\n",
      "Generating en split: 100%|██████████| 679738/679738 [00:00<00:00, 1643104.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"SoccerNet/SN-echoes\", \"whisper_v3\", split=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071192a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1\n",
      "and everything is possible\n",
      "england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1\n",
      "Felipe Luis for Azpilicueta and Zouma for Kejil, the rest of the team is the one that has been playing all season and almost immovable, so we certainly have a more than competitive team in Chelsea\n",
      "england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1\n",
      "César opened towards Eden Hazard, Hazard who was looking to gain the baseline there, leans on Cuadrado, Cuadrado who leaves that ball behind for Matic, Chelsea already dominating territorially after this first minute and a half of play\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(dataset[i][\"game\"])\n",
    "    print(dataset[i][\"text\"])  # [start, end, text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af276a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Loading SoccerNet-Echoes...\n",
      "📝 Writing labeled data to data/football_commentary_labelled.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labelling lines: 100%|██████████| 679738/679738 [01:07<00:00, 10049.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! Saved to: data/football_commentary_labelled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Path to output file\n",
    "output_file = \"data/football_commentary_labelled.csv\"\n",
    "\n",
    "# ✅ Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# 🧠 Heuristic labeler\n",
    "def label_line(text: str) -> str:\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if re.search(r'\\b(last season|last year|in \\d{4}|back in|previous game|previous match|earlier|in the past)\\b', text_lower):\n",
    "        return \"PAST\"\n",
    "    if re.search(r'\\b(born|grew up|idol|favorite|supports|childhood|as a kid|family|loves)\\b', text_lower):\n",
    "        return \"IRRELEVANT\"\n",
    "    return \"CURRENT\"\n",
    "\n",
    "# 📦 Load dataset\n",
    "print(\"📦 Loading SoccerNet-Echoes...\")\n",
    "dataset = load_dataset(\"SoccerNet/SN-echoes\", \"whisper_v3\", split=\"en\")\n",
    "\n",
    "# 💾 Write to CSV\n",
    "print(f\"📝 Writing labeled data to {output_file}...\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"game\", \"text\", \"label\"])\n",
    "    \n",
    "    for item in tqdm(dataset, desc=\"Labelling lines\"):\n",
    "        writer.writerow([item[\"game\"], item[\"text\"], label_line(item[\"text\"])])\n",
    "\n",
    "print(f\"\\n✅ Done! Saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d6b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70eaf530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "CURRENT       676935\n",
      "PAST            2003\n",
      "IRRELEVANT       800\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/football_commentary_labelled.csv\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801b4bb",
   "metadata": {},
   "source": [
    "## So under sample CURRENT -> 50K and over sample PAST, IRRELEVANT -> 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01bf92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading dataset...\n",
      "✅ Balanced dataset saved to: data/football_commentary_balanced.csv\n",
      "label\n",
      "PAST          50000\n",
      "CURRENT       50000\n",
      "IRRELEVANT    50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "\n",
    "# 📥 Load the dataset\n",
    "input_file = \"data/football_commentary_labelled.csv\"\n",
    "output_file = \"data/football_commentary_balanced.csv\"\n",
    "\n",
    "# Ensure path exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "print(\"🔄 Loading dataset...\")\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 🎯 Split by label\n",
    "df_current = df[df[\"label\"] == \"CURRENT\"]\n",
    "df_past = df[df[\"label\"] == \"PAST\"]\n",
    "df_irrelevant = df[df[\"label\"] == \"IRRELEVANT\"]\n",
    "\n",
    "# 🔽 Downsample CURRENT to 50,000\n",
    "df_current_down = resample(df_current,\n",
    "                           replace=False,\n",
    "                           n_samples=50000,\n",
    "                           random_state=42)\n",
    "\n",
    "# 🔼 Upsample PAST to 50,000\n",
    "df_past_up = resample(df_past,\n",
    "                      replace=True,\n",
    "                      n_samples=50000,\n",
    "                      random_state=42)\n",
    "\n",
    "# 🔼 Upsample IRRELEVANT to 50,000\n",
    "df_irrelevant_up = resample(df_irrelevant,\n",
    "                            replace=True,\n",
    "                            n_samples=50000,\n",
    "                            random_state=42)\n",
    "\n",
    "# 🧩 Combine all\n",
    "balanced_df = pd.concat([df_current_down, df_past_up, df_irrelevant_up])\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 💾 Save to CSV\n",
    "balanced_df.to_csv(output_file, index=False)\n",
    "print(f\"✅ Balanced dataset saved to: {output_file}\")\n",
    "print(balanced_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7b998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
